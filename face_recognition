import yt_dlp as youtube_dl
import cv2
import numpy as np
import face_recognition
from IPython.display import display, clear_output
from PIL import Image as PILImage
import time

#  Function to download YouTube video using yt-dlp
def download_youtube_video_yt_dlp(url):
    try:
        ydl_opts = {
            'format': 'best',
            'outtmpl': 'downloaded_video.mp4',
            'noplaylist': True
        }
        with youtube_dl.YoutubeDL(ydl_opts) as ydl:
            ydl.download([url])
        print("Video downloaded successfully!")
        return 'downloaded_video.mp4'
    except Exception as e:
        print(f"Error downloading video: {e}")
        return None

# Function to apply noise reduction and sharpening
def enhance_frame(frame):
    # Denoising to remove noise from the image
    denoised_frame = cv2.fastNlMeansDenoisingColored(frame, None, h=10, templateWindowSize=7, searchWindowSize=21)
    
    # Sharpening the image
    sharpening_kernel = np.array([[0, -1, 0], 
                                  [-1, 5, -1], 
                                  [0, -1, 0]])  # Simple sharpening kernel
    sharpened_frame = cv2.filter2D(denoised_frame, -1, sharpening_kernel)

    return sharpened_frame

# Function to calculate weighted average encoding
def weighted_average_encoding(existing_encoding, new_encoding, weight=0.7):
    return (weight * existing_encoding) + ((1 - weight) * new_encoding)

# Function to process video and detect faces
def process_video_with_face_detection(video_path):
    known_face_encodings = {}  # Dictionary to store ID -> average encoding
    known_face_ids = []  # List to track IDs
    next_face_id = 1
    tolerance = 0.4  # Stricter threshold for matching
    
    # Open the video file using OpenCV
    cap = cv2.VideoCapture(video_path)
    
    if not cap.isOpened():
        print("Error opening video file.")
        return
    
    frame_idx = 0
    while cap.isOpened():
        ret, frame = cap.read()
        
        if not ret:
            break
        
        # Resize the frame for faster processing
        small_frame = cv2.resize(frame, (0, 0), fx=0.5, fy=0.5)
        
        # Apply noise reduction and sharpening
        enhanced_frame = enhance_frame(small_frame)
        
        # Convert frame to RGB for face detection
        rgb_frame = cv2.cvtColor(enhanced_frame, cv2.COLOR_BGR2RGB)
        
        # Detect face locations and encodings
        face_locations = face_recognition.face_locations(rgb_frame)
        face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)
        
        face_ids = []
        for face_encoding, face_location in zip(face_encodings, face_locations):
            match_found = False
            closest_distance = float('inf')
            best_match_id = None

            # Check for matches with known faces
            for face_id in known_face_ids:
                # Compare face encoding with the weighted average encoding for this ID
                known_encoding = known_face_encodings[face_id]
                distance = face_recognition.face_distance([known_encoding], face_encoding)[0]
                
                # Track the closest match
                if distance < closest_distance:
                    closest_distance = distance
                    best_match_id = face_id

            # Use dynamic tolerance: match only if within threshold and closest distance
            if closest_distance < tolerance:
                face_id = best_match_id
                # Update the encoding with a weighted average for stability
                known_face_encodings[face_id] = weighted_average_encoding(known_face_encodings[face_id], face_encoding)
                match_found = True
            else:
                # Assign a new ID for a new face
                face_id = next_face_id
                known_face_ids.append(face_id)
                known_face_encodings[face_id] = face_encoding  # Start with the new encoding
                next_face_id += 1
            
            face_ids.append(face_id)
            
            # Draw rectangles around detected faces and display face ID
            top, right, bottom, left = face_location
            cv2.rectangle(enhanced_frame, (left, top), (right, bottom), (0, 255, 0), 2)
            cv2.putText(enhanced_frame, f"ID {face_id}", (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)

        if frame_idx % 10 == 0:
            # Display every 10th frame
            pil_img = PILImage.fromarray(cv2.cvtColor(enhanced_frame, cv2.COLOR_BGR2RGB))
            clear_output(wait=True)
            display(pil_img)
            time.sleep(0.1)
        
        frame_idx += 1
    
    cap.release()
    print("Finished processing video.")

# Input YouTube URL from user
youtube_url = input("Enter the YouTube video URL: ")

# Download the YouTube video using yt-dlp
video_path = download_youtube_video_yt_dlp(youtube_url)

if video_path:
    process_video_with_face_detection(video_path)
